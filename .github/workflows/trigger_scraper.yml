name: Trigger Scraper for Multiple Symbols and Save CSVs

on:
  schedule:
    - cron: '0 0 * * *'  # Runs at midnight UTC every day
  workflow_dispatch:  # Allows manual triggering of the workflow

jobs:
  trigger_scraper:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Create "Scraped data" Directory
      run: mkdir -p "Scraped data"

    - name: Define Symbols to Scrape
      id: symbols
      run: echo "SYMBOLS=NIFTY NIFTY500 MIDCAP50 BANKNIFTY NIFTYIT" >> $GITHUB_ENV

    - name: Trigger Scraper for Each Symbol and Download CSVs
      run: |
        for symbol in $SYMBOLS; do
          echo "Scraping data for $symbol..."
          output_file="Scraped data/${symbol}_stock_data.csv"
          curl --retry 5 --retry-delay 60 --max-time 600 -o "$output_file" "https://python-scraper-api-r1uj.onrender.com/api/$symbol"
          if [ $? -ne 0 ]; then
            echo "Failed to scrape data for $symbol"
            exit 1
          fi
        done

    - name: Verify CSV Files
      run: |
        for symbol in $SYMBOLS; do
          output_file="Scraped data/${symbol}_stock_data.csv"
          if [ ! -f "$output_file" ]; then
            echo "CSV file for $symbol not found! Scraper might have failed."
            exit 1
          fi
        done

    - name: Commit and Push Updated CSVs
      run: |
        git config --local user.name "github-actions"
        git config --local user.email "github-actions@github.com"
        git add "Scraped data/*.csv"
        git commit -m "Automated update of stock data for symbols: $SYMBOLS"
        git push
